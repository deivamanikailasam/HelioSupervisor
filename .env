# .env

# Limits and adjustable constants (optional; defaults used if unset)
MAX_TOKENS=8192
OLLAMA_NUM_CTX=4096
RECURSION_LIMIT=50
SUMMARIZE_MAX_WORDS=2000
SUMMARIZE_CRITIQUE_MAX_WORDS=2000
PLAN_MAX_STEPS=50
WEB_FETCH_MAX_CHARS=8000
WEB_FETCH_TIMEOUT=10
CODE_EXEC_TIMEOUT=10
MEMORY_RECENT_TURNS=6

# LLM (main provider: openai | ollama | google | perplexity)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.1

# Provider-specific models (when using google or perplexity)
GOOGLE_MODEL=gemini-1.5-pro
PERPLEXITY_MODEL=llama-3.1-sonar-small-128k-online

# RAG (local documents; opt-in per run in UI)
RAG_DOCS_DIR=memory/docs
RAG_INDEX_DIR=memory/rag_faiss
RAG_CHUNK_SIZE=800
RAG_CHUNK_OVERLAP=100
RAG_TOP_K=5
RAG_EMBEDDING_MODEL=BAAI/bge-base-en-v1.5
RAG_EMBEDDING_DEVICE=cpu
RAG_ALLOWED_EXTENSIONS=md,txt,pdf
RAG_NAIVE_CHUNK_MAX_CHARS=0
