# Helio Supervisor â€” copy to .env and adjust

# ----- Limits and behaviour (optional; defaults used if unset) -----
MAX_TOKENS=8192
OLLAMA_NUM_CTX=4096
RECURSION_LIMIT=50
SUMMARIZE_MAX_WORDS=2000
SUMMARIZE_CRITIQUE_MAX_WORDS=2000
PLAN_MAX_STEPS=10
WEB_FETCH_MAX_CHARS=8000
WEB_FETCH_TIMEOUT=10
CODE_EXEC_TIMEOUT=10
MEMORY_RECENT_TURNS=6

# ----- LLM (main provider: openai | ollama | google | perplexity) -----
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.1

# Provider-specific models (when using google or perplexity)
GOOGLE_MODEL=gemini-1.5-pro
PERPLEXITY_MODEL=llama-3.1-sonar-small-128k-online

# ----- API keys (required for cloud providers; leave empty for Ollama) -----
# OPENAI_API_KEY=sk-...
# GOOGLE_API_KEY=AIza...
# PERPLEXITY_API_KEY=pplx-...
